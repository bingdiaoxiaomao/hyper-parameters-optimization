{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.datasets import make_classification\n",
    "from bayes_opt import BayesianOptimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, target = make_classification(n_samples=10000,n_features=45,n_informative=12,n_redundant=7,random_state=2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = lgb.Dataset(data=data,label=target,free_raw_data=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_clf = lgb.LGBMClassifier(boosting_type='gbdt',is_unbalance=True,\n",
    "                             colsample_bytree=0.7,max_depth=3,\n",
    "                             learning_rate=0.1,min_child_weight=1.0,\n",
    "                             objective='binary',\n",
    "                             num_leaves=32,n_estimators=2000,\n",
    "                             reg_alpha=0.0,reg_lambda=0.0,\n",
    "                             subsample=0.9,random_state=2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgb_evaluate_cv(colsample_bytree=0.7,\n",
    "                    learning_rate=0.1,num_leaves=32,\n",
    "                    subsample=0.9,reg_alpha=0.0,\n",
    "                    reg_lambda=0.0,min_child_weight=0.0):\n",
    "    params = dict()\n",
    "    params['colsample_bytree'] = max(min(colsample_bytree,1),0)\n",
    "    params['learning_rate'] = max(min(learning_rate,1),0)\n",
    "    # 贝叶斯优化过程，num_leaves会按照float类型计算，在实际lgb计算过程中，必须以int形式输入\n",
    "    params['num_leaves'] = int(num_leaves)\n",
    "    params['subsample'] = max(min(subsample,1),0)\n",
    "    params['reg_alpha'] = max(0,reg_alpha)\n",
    "    params['reg_lambda'] = max(0,reg_lambda)\n",
    "    params['min_child_weight'] = int(min_child_weight)\n",
    "    params['is_unbalance'] = True\n",
    "    cv_result =  lgb.cv(params=params,train_set=dtrain,\n",
    "                        early_stopping_rounds=20,\n",
    "                        metrics='auc',nfold=5,\n",
    "                        num_boost_round=2000,\n",
    "                        verbose_eval=False,seed=1,show_stdv=True)                       \n",
    "    return cv_result['auc-mean'][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbBO = BayesianOptimization(f=lgb_evaluate_cv,\n",
    "                             pbounds={'colsample_bytree':(0.7,0.7),\n",
    "                                      'learning_rate':(0.01,0.2),\n",
    "                                      'num_leaves':(7,31),\n",
    "                                      'subsample':(0.7,0.95),\n",
    "                                      'reg_alpha':(0.0,0.0),\n",
    "                                      'reg_lambda':(0,0.0),\n",
    "                                      'min_child_weight':(1,1)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mInitialization\u001b[0m\n",
      "\u001b[94m---------------------------------------------------------------------------------------------------------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |   colsample_bytree |   learning_rate |   min_child_weight |   num_leaves |   reg_alpha |   reg_lambda |   subsample | \n",
      "    1 | 00m02s | \u001b[35m   0.98588\u001b[0m | \u001b[32m            0.7000\u001b[0m | \u001b[32m         0.1928\u001b[0m | \u001b[32m            1.0000\u001b[0m | \u001b[32m     15.6744\u001b[0m | \u001b[32m     0.0000\u001b[0m | \u001b[32m      0.0000\u001b[0m | \u001b[32m     0.8635\u001b[0m | \n",
      "    2 | 00m05s | \u001b[35m   0.98721\u001b[0m | \u001b[32m            0.7000\u001b[0m | \u001b[32m         0.0956\u001b[0m | \u001b[32m            1.0000\u001b[0m | \u001b[32m     25.3274\u001b[0m | \u001b[32m     0.0000\u001b[0m | \u001b[32m      0.0000\u001b[0m | \u001b[32m     0.7160\u001b[0m | \n",
      "    3 | 00m06s |    0.98652 |             0.7000 |          0.1636 |             1.0000 |      14.4048 |      0.0000 |       0.0000 |      0.8127 | \n",
      "    4 | 00m03s |    0.98705 |             0.7000 |          0.1456 |             1.0000 |      26.1786 |      0.0000 |       0.0000 |      0.8004 | \n",
      "    5 | 00m06s |    0.98577 |             0.7000 |          0.1984 |             1.0000 |      14.3739 |      0.0000 |       0.0000 |      0.9457 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Program Files (x86)\\anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00011974]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 55, 'nit': 7, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n",
      "D:\\Program Files (x86)\\anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py:335: UserWarning: Predicted variances smaller than 0. Setting those variances to 0.\n",
      "  warnings.warn(\"Predicted variances smaller than 0. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mBayesian Optimization\u001b[0m\n",
      "\u001b[94m---------------------------------------------------------------------------------------------------------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |   colsample_bytree |   learning_rate |   min_child_weight |   num_leaves |   reg_alpha |   reg_lambda |   subsample | \n",
      "    6 | 00m19s |    0.98607 |             0.7000 |          0.1900 |             1.0000 |       7.0095 |      0.0000 |       0.0000 |      0.7189 | \n",
      "    7 | 00m58s | \u001b[35m   0.98854\u001b[0m | \u001b[32m            0.7000\u001b[0m | \u001b[32m         0.0182\u001b[0m | \u001b[32m            1.0000\u001b[0m | \u001b[32m     30.9980\u001b[0m | \u001b[32m     0.0000\u001b[0m | \u001b[32m      0.0000\u001b[0m | \u001b[32m     0.7057\u001b[0m | \n",
      "    8 | 00m21s |    0.98633 |             0.7000 |          0.1999 |             1.0000 |      30.9147 |      0.0000 |       0.0000 |      0.7040 | \n",
      "    9 | 00m55s |    0.98525 |             0.7000 |          0.0110 |             1.0000 |      10.0637 |      0.0000 |       0.0000 |      0.7026 | \n",
      "   10 | 01m33s |    0.98842 |             0.7000 |          0.0108 |             1.0000 |      28.3916 |      0.0000 |       0.0000 |      0.7017 | \n"
     ]
    }
   ],
   "source": [
    "lgbBO.maximize(init_points=5,n_iter=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
